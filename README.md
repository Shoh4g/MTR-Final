# MTR-Final



 Text-to-speech app that guides the visually impaired (VIs) to their chosen exits in MTR Stations 
 
 
Architected a mapping platform, by leveraging BFS, DFS, Dijkstraâ€™s algorithm, and A* search algorithm, to provide personalized directions to VIs based on their step size, mode of
preference (stairs, elevators, escalators), and existing facilities (tactile paths), to lead them from the elevator in the station concourse to their preferred exit.

Capitalized React Native Paper material design library to make the UI more user-friendly for the VIs as well as integrated expo-speech to allow text-to-speech functionality in the app.
